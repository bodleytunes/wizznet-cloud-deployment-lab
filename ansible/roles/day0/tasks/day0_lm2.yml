---
#- debug:
#    var:
#      "{{ hostvars[inventory_hostname].groups.hetzner[1] }}"


- name: get lm2
  set_fact: 
    lm2: "{{ hostvars[inventory_hostname].groups.hetzner[0] }}"
  tags: always


- name: get all hetzner hosts
  set_fact: 
    hetzner_hosts: "{{ hostvars[inventory_hostname].groups.hetzner | list }}"

- name: set hostname 
  ansible.builtin.shell:
    cmd: salt-ssh -i "{{ lm2 }}" state.apply set_hostname_proxmox

- name: set hosts file and local dns
  ansible.builtin.shell:
    cmd: salt-ssh -i "{{ lm2 }}" state.apply all_hosts_file
  ignore_errors: True


#- name: Install ifupdown2
#  apt:
#    name: ifupdown2
#    state: present
#    dpkg_options: 'force-confold,force-confdef'
#  tags: 
#    - never
#  become: yes
#  delegate_to: "{{ lm2 }}"



- name: Install ifupdown2
  ansible.builtin.shell:
    cmd: salt-ssh -i "{{ lm2 }}" state.apply ifupdown2


- name: Delete Salt-key
  ansible.builtin.shell:
    cmd: salt-key -d "{{ lm2 }}" -y

- name: Install salt minion
  ansible.builtin.shell:
    cmd: salt-ssh -i "{{ lm2 }}" state.apply minion_control

- name: Accept new Salt-key
  ansible.builtin.shell:
    cmd: salt-key -a "{{ lm2 }}" -y

- name: Check for Minion to be active
  ansible.builtin.shell:
    cmd: salt "{{ lm2 }}" test.ping
  register: ping_result
  retries: 15
  delay: 4
  # check for the salt test.ping stdoutput to have a result of True before continuing
  until: '"True" in ping_result.stdout'

  

- name: cloud init disable
  ansible.builtin.shell:
    cmd: salt "{{ lm2 }}" state.apply cloud_init_disable
  ignore_errors: True

- name: Setup Networking /etc/network/interfaces
  ansible.builtin.shell:
    cmd: salt "{{ lm2 }}" state.apply networking_file
  ignore_errors: True

- name: Install All Initial pre-requisite Packages using APT
  ansible.builtin.shell:
    cmd: salt-ssh -i "{{ lm2 }}" state.apply initial_package_installs

- name: Syncronize Salt Custom Execution Modules
  ansible.builtin.shell:
    cmd: salt "{{ lm2 }}" saltutil.sync_modules

- name: Zerotier-one Networking - Stage1 - install Zerotier
  ansible.builtin.shell:
    cmd: salt "{{ lm2 }}" state.apply zerotier_one_stage1
  ignore_errors: True

- name: Zerotier-one Networking - Stage2 - Join Network, Authorize, Advertise Networks
  ansible.builtin.shell:
    cmd: salt "{{ lm2 }}" state.apply zerotier_one_stage2
  ignore_errors: True

- name: Install Proxmox-VE
  ansible.builtin.shell:
    cmd: salt "{{ lm2 }}" state.apply install_proxmox
  ignore_errors: True

- name: REBOOT SERVER
  ansible.builtin.shell:
    cmd: salt "{{ lm2 }}" system.reboot

- name: Wait 300 seconds for the rebooted server to come back online -- port 22 open 
  wait_for:
    port: 22
    host: "10.55.0.122"
    #host: "ns31050143.ip-51-77-116.eu"
    host: "{{ hostvars['lm2'].ip }}"
    delay: 10
    timeout: 800
    msg: waited for ssh port  
  ignore_errors: True
# call handler to reboot server (handler is called "restart servers")
#- name: Reboot Server
#  command: /bin/true
#  notify: "restart servers"
#  ignore_errors: True

## need to make sure this runs as there is a delay so wait for good return code

- name: Kernel Modules
  ansible.builtin.shell:
    cmd: salt "{{ lm2 }}" state.apply kernel_modules
  ignore_errors: True
  tags: kmods
  retries: 5
  delay: 5
  register: result
  until: result.rc == 0

- name: Disk Partitioning
  ansible.builtin.shell:
    cmd: salt "{{ lm2 }}" state.apply storage_disk_partitioning_zpool

- name: LXD Install via Snap
  ansible.builtin.shell:
    cmd: salt "{{ lm2 }}" state.apply lxd_snap

- name: LXD Configuration
  ansible.builtin.shell:
    cmd: salt "{{ lm2 }}" state.apply lxd_configuration
  ignore_errors: True

- name: UFW Firewall Configuration
  ansible.builtin.shell:
    cmd: salt "{{ lm2 }}" state.apply ufw
  ignore_errors: True

- name: Wait 15 seconds for -- port 22 open after ufw
  wait_for:
    port: 22
    #host: "10.55.0.122"
    host: "{{ hostvars['lm2'].ip }}"
    delay: 10
    timeout: 15
    msg: waited for ssh port  
  ignore_errors: True


- name: Backblaze S3FS Storage setup for Backups
  ansible.builtin.shell:
    cmd: salt "{{ lm2 }}" state.apply backblaze_s3fs
  ignore_errors: True


- name: Setup Networking /etc/network/interfaces
  ansible.builtin.shell:
    cmd: salt "{{ lm2 }}" state.apply networking_file
  ignore_errors: True

- name: Sysctl Flags
  ansible.builtin.shell:
    cmd: salt "{{ lm2 }}" state.apply set_sysctl_conf
  ignore_errors: True

## UDPATE TO LATEST 7.4 FRR OR CONFIG IS NOT ACCEPTED

- name: Dist upgrade
  apt:
    upgrade: dist
    dpkg_options: 'force-confold,force-confdef'
  tags: dist-upgrade

# configure then restart the service via handler
- name: Free Range Routing Configuration
  ansible.builtin.shell:
    cmd: salt "{{ lm2 }}" state.apply frr_configuration
  ignore_errors: True
  notify: "restart frr"
  tags: "configure-frr"
  
  
- name: Setup Users and Public Keys
  ansible.builtin.shell:
    cmd: salt "{{ lm2 }}" state.apply users
  ignore_errors: True

- name: Setup Users in Visudo (Sudoers)
  ansible.builtin.shell:
    cmd: salt "{{ lm2 }}" state.apply users_visudo
  ignore_errors: True

- name: Setup Users in PVE
  ansible.builtin.shell:
    cmd: salt "{{ lm2 }}" state.apply users_pve
  ignore_errors: True

- name: Setup GlusterFS Storage
  ansible.builtin.shell:
    cmd: salt "{{ lm2 }}" state.apply storage_gluster
  ignore_errors: True

- name: Setup GlusterFS Storage Gluster Client and Fstab Mount for GV1
  ansible.builtin.shell:
    cmd: salt "{{ lm2 }}" state.apply storage_gluster_client
  ignore_errors: True


- name: Setup Samba Shares
  ansible.builtin.shell:
    cmd: salt "{{ lm2 }}" state.apply storage_samba_shares
  ignore_errors: True

### on lm2 master only

- name: Proxmox Cluster Pre-requisites (Master only)
  ansible.builtin.shell:
    cmd: salt "{{ lm2 }}" state.apply proxmox_cluster_pre_req
  ignore_errors: True

- name: Proxmox Cluster Create (Master only)
  ansible.builtin.shell:
    cmd: salt "{{ lm2 }}" state.apply proxmox_cluster_create
  ignore_errors: True

- name: Setup GlusterFS Storage
  ansible.builtin.shell:
    cmd: salt "{{ lm2 }}" state.apply storage_gluster
  ignore_errors: True
  tags:
    - glusterfs-storage
    - glusterfs

- name: Setup GlusterFS Storage Gluster Client and Fstab Mount for GV1
  ansible.builtin.shell:
    cmd: salt "{{ lm2 }}" state.apply storage_gluster_client
  ignore_errors: True
  tags:
    - glusterfs-client
    - glusterfs


- name: Setup LizardFS Storage
  ansible.builtin.shell:
    cmd: salt "{{ lm2 }}" state.apply states.lizardfs.lizardfs_server
  ignore_errors: True

- name: Setup LizardFS Client
  ansible.builtin.shell:
    cmd: salt "{{ lm2 }}" state.apply states.lizardfs.lizardfs_client
  ignore_errors: True


# last storage prox
- name: Proxmox Storage Configuration File
  ansible.builtin.shell:
    cmd: salt "{{ lm2 }}" state.apply proxmox_storage_config
  ignore_errors: True
  


# post task dist-upgrade to install FRR correct version

- name: Dist upgrade
  apt:
    upgrade: dist
    update_cache: yes
    dpkg_options: 'force-confold,force-confdef'

# working salt dist-upgrade
- name: Dist upgrade to get latest FRR to be compatible with config
  ansible.builtin.shell:
    cmd: salt "{{ lm2 }}" state.apply dist_upgrade_non_interactive
  ignore_errors: True

- name: Free Range Routing Configuration
  ansible.builtin.shell:
    cmd: salt "{{ lm2 }}" state.apply frr_configuration
  ignore_errors: True
  notify: "restart frr"
  tags: configure-frr

- name: Free Range Routing Manual restart
  ansible.builtin.shell:
    cmd: salt "{{ lm2 }}" cmd.run "systemctl restart frr"
  ignore_errors: True
